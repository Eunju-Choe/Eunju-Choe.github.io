---
title: 수강 기록 정리 - BDM 부정거래 탐지
author: Eunju Choe
category: Project
tags: [Analytics, Python, Preprocessing, Machine Learning, Data Mining, Lecture]
img: ":20230317.png"
date: 2023-03-17 15:47:00 +0900
---
<p align="center"><img src="https://eunju-choe.github.io/assets/img/posts/20230317.png" width='50%'></p>

오늘은 "비즈니스 데이터마이닝" 수업을 들을 때 과제로 제출했던 코드를 조금 다듬어서 정리해보도록 하겠습니다. 과거에 작성했던 파일이기에 설명이나 논리가 부족할 수 있습니다.


```python
import pandas as pd
import numpy as np

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report

import warnings
warnings.filterwarnings('ignore')
```

# 1. 데이터 불러오기


```python
df = pd.read_csv('creditcard.csv')
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>-1.359807</td>
      <td>-0.072781</td>
      <td>2.536347</td>
      <td>1.378155</td>
      <td>-0.338321</td>
      <td>0.462388</td>
      <td>0.239599</td>
      <td>0.098698</td>
      <td>0.363787</td>
      <td>...</td>
      <td>-0.018307</td>
      <td>0.277838</td>
      <td>-0.110474</td>
      <td>0.066928</td>
      <td>0.128539</td>
      <td>-0.189115</td>
      <td>0.133558</td>
      <td>-0.021053</td>
      <td>149.62</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>1.191857</td>
      <td>0.266151</td>
      <td>0.166480</td>
      <td>0.448154</td>
      <td>0.060018</td>
      <td>-0.082361</td>
      <td>-0.078803</td>
      <td>0.085102</td>
      <td>-0.255425</td>
      <td>...</td>
      <td>-0.225775</td>
      <td>-0.638672</td>
      <td>0.101288</td>
      <td>-0.339846</td>
      <td>0.167170</td>
      <td>0.125895</td>
      <td>-0.008983</td>
      <td>0.014724</td>
      <td>2.69</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>-1.358354</td>
      <td>-1.340163</td>
      <td>1.773209</td>
      <td>0.379780</td>
      <td>-0.503198</td>
      <td>1.800499</td>
      <td>0.791461</td>
      <td>0.247676</td>
      <td>-1.514654</td>
      <td>...</td>
      <td>0.247998</td>
      <td>0.771679</td>
      <td>0.909412</td>
      <td>-0.689281</td>
      <td>-0.327642</td>
      <td>-0.139097</td>
      <td>-0.055353</td>
      <td>-0.059752</td>
      <td>378.66</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>-0.966272</td>
      <td>-0.185226</td>
      <td>1.792993</td>
      <td>-0.863291</td>
      <td>-0.010309</td>
      <td>1.247203</td>
      <td>0.237609</td>
      <td>0.377436</td>
      <td>-1.387024</td>
      <td>...</td>
      <td>-0.108300</td>
      <td>0.005274</td>
      <td>-0.190321</td>
      <td>-1.175575</td>
      <td>0.647376</td>
      <td>-0.221929</td>
      <td>0.062723</td>
      <td>0.061458</td>
      <td>123.50</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.0</td>
      <td>-1.158233</td>
      <td>0.877737</td>
      <td>1.548718</td>
      <td>0.403034</td>
      <td>-0.407193</td>
      <td>0.095921</td>
      <td>0.592941</td>
      <td>-0.270533</td>
      <td>0.817739</td>
      <td>...</td>
      <td>-0.009431</td>
      <td>0.798278</td>
      <td>-0.137458</td>
      <td>0.141267</td>
      <td>-0.206010</td>
      <td>0.502292</td>
      <td>0.219422</td>
      <td>0.215153</td>
      <td>69.99</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 31 columns</p>
</div>



데이터는 캐글에 있는 [Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)을 사용하였습니다. 신용카드 데이터에서 부정 거래를 탐지하는 것이 이번 프로젝트의 목표입니다.

#### 변수 설명

![image.png](https://eunju-choe.github.io/assets/img/posts/20230317/image.png)

# 2. 데이터 구조 파악


```python
df.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Time</th>
      <th>V1</th>
      <th>V2</th>
      <th>V3</th>
      <th>V4</th>
      <th>V5</th>
      <th>V6</th>
      <th>V7</th>
      <th>V8</th>
      <th>V9</th>
      <th>...</th>
      <th>V21</th>
      <th>V22</th>
      <th>V23</th>
      <th>V24</th>
      <th>V25</th>
      <th>V26</th>
      <th>V27</th>
      <th>V28</th>
      <th>Amount</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>284807.000000</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>...</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>2.848070e+05</td>
      <td>284807.000000</td>
      <td>284807.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>94813.859575</td>
      <td>1.165980e-15</td>
      <td>3.416908e-16</td>
      <td>-1.373150e-15</td>
      <td>2.086869e-15</td>
      <td>9.604066e-16</td>
      <td>1.490107e-15</td>
      <td>-5.556467e-16</td>
      <td>1.177556e-16</td>
      <td>-2.406455e-15</td>
      <td>...</td>
      <td>1.656562e-16</td>
      <td>-3.444850e-16</td>
      <td>2.578648e-16</td>
      <td>4.471968e-15</td>
      <td>5.340915e-16</td>
      <td>1.687098e-15</td>
      <td>-3.666453e-16</td>
      <td>-1.220404e-16</td>
      <td>88.349619</td>
      <td>0.001727</td>
    </tr>
    <tr>
      <th>std</th>
      <td>47488.145955</td>
      <td>1.958696e+00</td>
      <td>1.651309e+00</td>
      <td>1.516255e+00</td>
      <td>1.415869e+00</td>
      <td>1.380247e+00</td>
      <td>1.332271e+00</td>
      <td>1.237094e+00</td>
      <td>1.194353e+00</td>
      <td>1.098632e+00</td>
      <td>...</td>
      <td>7.345240e-01</td>
      <td>7.257016e-01</td>
      <td>6.244603e-01</td>
      <td>6.056471e-01</td>
      <td>5.212781e-01</td>
      <td>4.822270e-01</td>
      <td>4.036325e-01</td>
      <td>3.300833e-01</td>
      <td>250.120109</td>
      <td>0.041527</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>-5.640751e+01</td>
      <td>-7.271573e+01</td>
      <td>-4.832559e+01</td>
      <td>-5.683171e+00</td>
      <td>-1.137433e+02</td>
      <td>-2.616051e+01</td>
      <td>-4.355724e+01</td>
      <td>-7.321672e+01</td>
      <td>-1.343407e+01</td>
      <td>...</td>
      <td>-3.483038e+01</td>
      <td>-1.093314e+01</td>
      <td>-4.480774e+01</td>
      <td>-2.836627e+00</td>
      <td>-1.029540e+01</td>
      <td>-2.604551e+00</td>
      <td>-2.256568e+01</td>
      <td>-1.543008e+01</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>54201.500000</td>
      <td>-9.203734e-01</td>
      <td>-5.985499e-01</td>
      <td>-8.903648e-01</td>
      <td>-8.486401e-01</td>
      <td>-6.915971e-01</td>
      <td>-7.682956e-01</td>
      <td>-5.540759e-01</td>
      <td>-2.086297e-01</td>
      <td>-6.430976e-01</td>
      <td>...</td>
      <td>-2.283949e-01</td>
      <td>-5.423504e-01</td>
      <td>-1.618463e-01</td>
      <td>-3.545861e-01</td>
      <td>-3.171451e-01</td>
      <td>-3.269839e-01</td>
      <td>-7.083953e-02</td>
      <td>-5.295979e-02</td>
      <td>5.600000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>84692.000000</td>
      <td>1.810880e-02</td>
      <td>6.548556e-02</td>
      <td>1.798463e-01</td>
      <td>-1.984653e-02</td>
      <td>-5.433583e-02</td>
      <td>-2.741871e-01</td>
      <td>4.010308e-02</td>
      <td>2.235804e-02</td>
      <td>-5.142873e-02</td>
      <td>...</td>
      <td>-2.945017e-02</td>
      <td>6.781943e-03</td>
      <td>-1.119293e-02</td>
      <td>4.097606e-02</td>
      <td>1.659350e-02</td>
      <td>-5.213911e-02</td>
      <td>1.342146e-03</td>
      <td>1.124383e-02</td>
      <td>22.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>139320.500000</td>
      <td>1.315642e+00</td>
      <td>8.037239e-01</td>
      <td>1.027196e+00</td>
      <td>7.433413e-01</td>
      <td>6.119264e-01</td>
      <td>3.985649e-01</td>
      <td>5.704361e-01</td>
      <td>3.273459e-01</td>
      <td>5.971390e-01</td>
      <td>...</td>
      <td>1.863772e-01</td>
      <td>5.285536e-01</td>
      <td>1.476421e-01</td>
      <td>4.395266e-01</td>
      <td>3.507156e-01</td>
      <td>2.409522e-01</td>
      <td>9.104512e-02</td>
      <td>7.827995e-02</td>
      <td>77.165000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>172792.000000</td>
      <td>2.454930e+00</td>
      <td>2.205773e+01</td>
      <td>9.382558e+00</td>
      <td>1.687534e+01</td>
      <td>3.480167e+01</td>
      <td>7.330163e+01</td>
      <td>1.205895e+02</td>
      <td>2.000721e+01</td>
      <td>1.559499e+01</td>
      <td>...</td>
      <td>2.720284e+01</td>
      <td>1.050309e+01</td>
      <td>2.252841e+01</td>
      <td>4.584549e+00</td>
      <td>7.519589e+00</td>
      <td>3.517346e+00</td>
      <td>3.161220e+01</td>
      <td>3.384781e+01</td>
      <td>25691.160000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>8 rows × 31 columns</p>
</div>




```python
df.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 284807 entries, 0 to 284806
    Data columns (total 31 columns):
     #   Column  Non-Null Count   Dtype  
    ---  ------  --------------   -----  
     0   Time    284807 non-null  float64
     1   V1      284807 non-null  float64
     2   V2      284807 non-null  float64
     3   V3      284807 non-null  float64
     4   V4      284807 non-null  float64
     5   V5      284807 non-null  float64
     6   V6      284807 non-null  float64
     7   V7      284807 non-null  float64
     8   V8      284807 non-null  float64
     9   V9      284807 non-null  float64
     10  V10     284807 non-null  float64
     11  V11     284807 non-null  float64
     12  V12     284807 non-null  float64
     13  V13     284807 non-null  float64
     14  V14     284807 non-null  float64
     15  V15     284807 non-null  float64
     16  V16     284807 non-null  float64
     17  V17     284807 non-null  float64
     18  V18     284807 non-null  float64
     19  V19     284807 non-null  float64
     20  V20     284807 non-null  float64
     21  V21     284807 non-null  float64
     22  V22     284807 non-null  float64
     23  V23     284807 non-null  float64
     24  V24     284807 non-null  float64
     25  V25     284807 non-null  float64
     26  V26     284807 non-null  float64
     27  V27     284807 non-null  float64
     28  V28     284807 non-null  float64
     29  Amount  284807 non-null  float64
     30  Class   284807 non-null  int64  
    dtypes: float64(30), int64(1)
    memory usage: 67.4 MB


# 3. 데이터 탐색

## 3.1. Class - 타겟변수


```python
num_1 = len(df[df['Class']==1])
ratio_1 = num_1 / len(df) * 100
print(f'부정 거래의 비율 : {ratio_1:.2f}%({num_1}건)')

sns.countplot(x='Class', data=df);
```

    부정 거래의 비율 : 0.17%(492건)



    
![png](https://eunju-choe.github.io/assets/img/posts/20230317/output_12_1.png)
    


전체 거래 중 부정 거래의 비율이 0.17%로 범주가 불균형하게 분포하고 있음을 확인할 수 있습니다. 이렇게 Imbalanced Data인 경우에는 모델링 과정에서 소수 범주가 무시되는 문제가 발생할 수 있습니다. 따라서 학습 과정에서 오버샘플링을 실시할 계획입니다. 또한 하나의 범주에 데이터가 집중되어있는 경우에는 평가 지표를 사용할 때에도 유의해야합니다. 평가 과정에서는 Accuracy가 아닌 F1 Score를 이용하여 모델을 평가하도록 하겠습니다.

## 3.2. Time


```python
sns.displot(df['Time']);
```


    
![png](https://eunju-choe.github.io/assets/img/posts/20230317/output_15_0.png)
    


Time 변수는 데이터셋의 첫 번째 거래가 발생한 시각과 해당 거래가 발생한 시각의 차이를 보여주는 변수로, 절대적인 거래 발생 시각이 아닌 상대적인 거래 발생 시각을 표현합니다. 저는 이 변수가 의미하는 바가 명확하지 않고, 유의미한 정보가 아니라고 생각하여 이상거래 탐지에는 사용하지 않았습니다.


```python
df = df.drop('Time', axis=1)
```

## 3.3 V1 ~ V28


```python
cols = df.loc[:, "V1":"V28"]
f, ax = plt.subplots(7, 4, figsize=(15, 25))
for i, col in enumerate(cols):
    row = i//4
    Col = i%4
    sns.distplot(df[col], ax=ax[row,Col])
```


    
![png](https://eunju-choe.github.io/assets/img/posts/20230317/output_19_0.png)
    


## 3.4 Amount


```python
sns.distplot(df['Amount']);
```


    
![png](https://eunju-choe.github.io/assets/img/posts/20230317/output_21_0.png)
    



```python
df['Amount'] = np.log1p(df['Amount'])
sns.distplot(df['Amount']);
```


    
![png](output_22_0.png)
    


분포가 왼쪽으로 치우쳐 있어 로그화를 통해 정규분포와 유사한 분포로 바꿔주었습니다.

# 4. 데이터 전처리


```python
plt.figure(figsize=(15, 7))
df.iloc[:,0:-2].boxplot();
```


    
![png](https://eunju-choe.github.io/assets/img/posts/20230317/output_25_0.png)
    


boxplot을 통해 불연속적으로 떨어져있는 극단치가 있는 변수를 확인할 수 있습니다.


```python
plt.figure(figsize=(15, 7))
plt.boxplot(df.loc[:, 'V1':'V28'])
plt.plot([None] + df.loc[274771, "V1":"V28"].tolist(), 'rx')
plt.xticks(ticks=range(1, 29), labels=df.columns[:28])
plt.grid()
plt.show()
```


    
![png](https://eunju-choe.github.io/assets/img/posts/20230317/output_27_0.png)
    


이상치 처리를 하기 전 Index 274771의 값들이 여러 변수에서 극단치로 발견되는 것을 확인할 수 있었습니다. 이와 같은 방식으로 다른 데이터를 찾고 7개의 데이터를 제거해주었습니다.


```python
df = df.drop([274771, 65423, 39769, 118764, 58465, 91896, 151296], axis=0)
```


```python
plt.figure(figsize=(15, 7))
df.iloc[:,0:-2].boxplot();
```


    
![png](https://eunju-choe.github.io/assets/img/posts/20230317/output_30_0.png)
    


이상치 처리 후 분포의 모습입니다. 이외의 값들은 이상치 처리를 하지 않았습니다.

# 5. 모델 생성 및 평가

## 5.1. train test split


```python
X = df.drop('Class', axis=1)
y = df['Class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y)
```

## 5.2. oversampling


```python
ros = RandomOverSampler()
X_resampled, y_resampled = ros.fit_resample(X_train, y_train)
```

앞서 언급한 범주불균형으로 인해 샘플링 작업이 필요합니다. 샘플링은 크게 Oversampling과 Undersampling으로 구분할 수 있습니다. 이번에는 소수 범주의 데이터가 충분하지 않기 때문에 오버샘플링을 사용하였습니다. 이때 test 데이터에는 샘플링을 하지 않아야하기 때문에, train test split을 수행한 이후 샘플링을 하는 것에 유의해야합니다.

## 5.3. 모델생성 및 성과 평가


```python
# DecisionTreeClassifier 객체 생성
dt_clf = DecisionTreeClassifier()

# 학습 수행 및 예측
dt_clf.fit(X_resampled, y_resampled)
dt_pred = dt_clf.predict(X_test)

# 성과 평가
print('### 정확도 : {0:.4f}    F1-score : {1:.4f}'.format(accuracy_score(y_test, dt_pred), f1_score(y_test, dt_pred)), '\n')
print('### 정오행렬표\n', confusion_matrix(y_test, dt_pred), '\n')
print('### 분류 리포트\n', classification_report(y_test, dt_pred, target_names = ['Class 0', 'Class 1']))
```

    ### 정확도 : 0.9990    F1-score : 0.7005 
    
    ### 정오행렬표
     [[56832    30]
     [   29    69]] 
    
    ### 분류 리포트
                   precision    recall  f1-score   support
    
         Class 0       1.00      1.00      1.00     56862
         Class 1       0.70      0.70      0.70        98
    
        accuracy                           1.00     56960
       macro avg       0.85      0.85      0.85     56960
    weighted avg       1.00      1.00      1.00     56960
    


Decision Tree를 이용하여 이진 분류를 실시한 결과 F1-score가 0.7이 나왔습니다.
